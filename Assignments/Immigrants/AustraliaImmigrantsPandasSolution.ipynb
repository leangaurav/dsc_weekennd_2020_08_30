{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read sheet \"Australia by Residence\" from Australia.xlsx\n",
    "- Ignore the first 20 rows.\n",
    "- List all Column and Row indexes(Print their names)\n",
    "\n",
    "Dataset Analysis\n",
    "- Describe the dataset\n",
    "- Use values and index attributes on both Row and Column Indexes\n",
    "- Check Shape, Datatypes and other attributes and observe the datatype of each columns' data\n",
    "  \n",
    "\n",
    "Drop\n",
    "- Delete all Data where the Type = \"Emigrants\" or Type is not \"Immigrants\" (Row Deletion)\n",
    "- Find columns for which more than 50% data is missing and drop them (Column Deletion)\n",
    "- Drop Unnessary Columns: Type, Coverage, Area, Reg, Dev (Column deletion)\n",
    "    Your columns should now look like \"OdName,AreaName,RegName,DevName,1980 ... 2008\"\n",
    "\n",
    "Rename\n",
    "- Rename columns :OdName -> Country; RegName -> Region\n",
    "- Convert Column Names with Int type to Strings to avoid index errors with string indexing \"1980, 1981 etc.\" => \" '1980', '1981' ... \" (Use rename)\n",
    "- Find Total number of immigrants for all years, and create a new column Total in data Frame\n",
    "\n",
    "Head Tail Sort\n",
    "- Sort Data by the new column Total in descending order and analyze the fist few rows. (get first few rows using head)\n",
    "    - find something weird in the dataset ? Delete that row 'world'\n",
    "- Analyze last few rows also in the sorted result (Don't sort inplace)\n",
    "\n",
    "- Check if these have all unique values or not:\n",
    "    - countries\n",
    "    - continents (AreaName)\n",
    "    - country continent pairs\n",
    "\n",
    "\n",
    "- Find countries for which no of immigrants for all years is 0\n",
    "- Find count of above countries\n",
    "- Find countries for which no of immigrants is 0 for any year\n",
    "\n",
    "Save Data\n",
    "- Drop the row where AreaName is 'World'\n",
    "- Save the dataset to a new file AustraliaFiltered.xlsx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sheet \"Australia by Residence\" from Australia.xlsx\n",
    "# Ignore the first 20 rows.\n",
    "df = pd.read_excel('Australia.xlsx', sheet_name = 'Australia by Residence', skiprows = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([    'Type', 'Coverage',   'OdName',     'AREA', 'AreaName',      'REG',\n",
      "        'RegName',      'DEV',  'DevName',       1980,       1981,       1982,\n",
      "             1983,       1984,       1985,       1986,       1987,       1988,\n",
      "             1989,       1990,       1991,       1992,       1993,       1994,\n",
      "             1995,       1996,       1997,       1998,       1999,       2000,\n",
      "             2001,       2002,       2003,       2004,       2005,       2006,\n",
      "             2007,       2008,       2009,       2010,       2011,       2012,\n",
      "             2013],\n",
      "      dtype='object')\n",
      "RangeIndex(start=0, stop=448, step=1)\n",
      "\n",
      "\n",
      "['Type' 'Coverage' 'OdName' 'AREA' 'AreaName' 'REG' 'RegName' 'DEV'\n",
      " 'DevName' 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991\n",
      " 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005\n",
      " 2006 2007 2008 2009 2010 2011 2012 2013]\n",
      "\n",
      "\n",
      "        Type Coverage          OdName  AREA AreaName   REG          RegName  \\\n",
      "0  Emigrants     Both     Afghanistan   935     Asia  5501    Southern Asia   \n",
      "1  Emigrants     Both         Albania   908   Europe   925  Southern Europe   \n",
      "2  Emigrants     Both         Algeria   903   Africa   912  Northern Africa   \n",
      "3  Emigrants     Both  American Samoa   909  Oceania   957        Polynesia   \n",
      "4  Emigrants     Both         Andorra   908   Europe   925  Southern Europe   \n",
      "\n",
      "   DEV             DevName  1980  ...  2004  2005  2006  2007  2008  2009  \\\n",
      "0  902  Developing regions     0  ...    80   120    70    80   120    ..   \n",
      "1  901   Developed regions     0  ...    30    40    30    30    30    ..   \n",
      "2  902  Developing regions    20  ...    20    20    30    40    50    ..   \n",
      "3  902  Developing regions    10  ...     0     0     0     0     0    ..   \n",
      "4  901   Developed regions     0  ...     0     0     0     0     0    ..   \n",
      "\n",
      "   2010  2011  2012  2013  \n",
      "0    ..    ..    ..    ..  \n",
      "1    ..    ..    ..    ..  \n",
      "2    ..    ..    ..    ..  \n",
      "3    ..    ..    ..    ..  \n",
      "4    ..    ..    ..    ..  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# List all Column and Row indexes(Print their names)\n",
    "print(df.columns)\n",
    "print(df.index)\n",
    "\n",
    "print();print()\n",
    "print(df.columns.values)\n",
    "\n",
    "print();print()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Type Coverage    OdName        AREA AreaName          REG  \\\n",
      "count         448      448       448  448.000000      448   448.000000   \n",
      "unique          2        1       224         NaN        7          NaN   \n",
      "top     Emigrants     Both  Kiribati         NaN   Africa          NaN   \n",
      "freq          224      448         2         NaN      112          NaN   \n",
      "mean          NaN      NaN       NaN  912.955357      NaN  1208.040179   \n",
      "std           NaN      NaN       NaN   15.019682      NaN  1109.669573   \n",
      "min           NaN      NaN       NaN  903.000000      NaN   905.000000   \n",
      "25%           NaN      NaN       NaN  903.750000      NaN   914.000000   \n",
      "50%           NaN      NaN       NaN  908.000000      NaN   922.000000   \n",
      "75%           NaN      NaN       NaN  909.000000      NaN   926.000000   \n",
      "max           NaN      NaN       NaN  999.000000      NaN  5501.000000   \n",
      "\n",
      "          RegName         DEV             DevName           1980  ...  \\\n",
      "count         448  448.000000                 448     448.000000  ...   \n",
      "unique         23         NaN                   3            NaN  ...   \n",
      "top     Caribbean         NaN  Developing regions            NaN  ...   \n",
      "freq           46         NaN                 344            NaN  ...   \n",
      "mean          NaN  902.642857                 NaN    1228.348214  ...   \n",
      "std           NaN    9.165500                 NaN   10145.734028  ...   \n",
      "min           NaN  901.000000                 NaN       0.000000  ...   \n",
      "25%           NaN  902.000000                 NaN       0.000000  ...   \n",
      "50%           NaN  902.000000                 NaN      10.000000  ...   \n",
      "75%           NaN  902.000000                 NaN     130.000000  ...   \n",
      "max           NaN  999.000000                 NaN  184290.000000  ...   \n",
      "\n",
      "                 2004           2005           2006           2007  \\\n",
      "count      448.000000     448.000000     448.000000     448.000000   \n",
      "unique            NaN            NaN            NaN            NaN   \n",
      "top               NaN            NaN            NaN            NaN   \n",
      "freq              NaN            NaN            NaN            NaN   \n",
      "mean      2514.241071    2545.357143    2709.866071    3023.348214   \n",
      "std      19834.528214   20203.441660   21786.641444   24542.748186   \n",
      "min          0.000000       0.000000       0.000000       0.000000   \n",
      "25%         10.000000      10.000000      10.000000      10.000000   \n",
      "50%         50.000000      50.000000      60.000000      70.000000   \n",
      "75%        400.000000     410.000000     455.000000     480.000000   \n",
      "max     350990.000000  363470.000000  402210.000000  460650.000000   \n",
      "\n",
      "                 2008  2009  2010  2011  2012  2013  \n",
      "count      448.000000   448   448   448   448   448  \n",
      "unique            NaN     1     1     1     1     1  \n",
      "top               NaN    ..    ..    ..    ..    ..  \n",
      "freq              NaN   448   448   448   448   448  \n",
      "mean      3376.116071   NaN   NaN   NaN   NaN   NaN  \n",
      "std      27950.462893   NaN   NaN   NaN   NaN   NaN  \n",
      "min          0.000000   NaN   NaN   NaN   NaN   NaN  \n",
      "25%         10.000000   NaN   NaN   NaN   NaN   NaN  \n",
      "50%         75.000000   NaN   NaN   NaN   NaN   NaN  \n",
      "75%        512.500000   NaN   NaN   NaN   NaN   NaN  \n",
      "max     535970.000000   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[11 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "print(df.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type' 'Coverage' 'OdName' 'AREA' 'AreaName' 'REG' 'RegName' 'DEV'\n",
      " 'DevName' 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991\n",
      " 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005\n",
      " 2006 2007 2008 2009 2010 2011 2012 2013]\n",
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__bytes__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__init__', '__init_subclass__', '__inv__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmul__', '__rpow__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__unicode__', '__weakref__', '__xor__', '_accessors', '_add_comparison_methods', '_add_logical_methods', '_add_logical_methods_disabled', '_add_numeric_methods', '_add_numeric_methods_add_sub_disabled', '_add_numeric_methods_binary', '_add_numeric_methods_disabled', '_add_numeric_methods_unary', '_assert_can_do_op', '_assert_can_do_setop', '_assert_take_fillable', '_attributes', '_can_hold_identifiers_and_holds_name', '_can_hold_na', '_can_reindex', '_cleanup', '_coerce_scalar_to_index', '_coerce_to_ndarray', '_comparables', '_concat', '_concat_same_dtype', '_constructor', '_convert_arr_indexer', '_convert_can_do_setop', '_convert_for_op', '_convert_index_indexer', '_convert_list_indexer', '_convert_listlike_indexer', '_convert_scalar_indexer', '_convert_slice_indexer', '_convert_tolerance', '_data', '_defer_to_indexing', '_deprecations', '_dir_additions', '_dir_deletions', '_engine', '_engine_type', '_evaluate_with_datetime_like', '_evaluate_with_timedelta_like', '_filter_indexer_tolerance', '_format_attrs', '_format_data', '_format_native_types', '_format_space', '_format_with_header', '_formatter_func', '_get_attributes_dict', '_get_fill_indexer', '_get_fill_indexer_searchsorted', '_get_grouper_for_level', '_get_level_number', '_get_level_values', '_get_loc_only_exact_matches', '_get_names', '_get_nearest_indexer', '_get_reconciled_name_object', '_get_string_slice', '_get_unique_index', '_has_complex_internals', '_id', '_infer_as_myclass', '_inner_indexer', '_invalid_indexer', '_is_homogeneous_type', '_is_memory_usage_qualified', '_is_numeric_dtype', '_is_strictly_monotonic_decreasing', '_is_strictly_monotonic_increasing', '_isnan', '_join_level', '_join_monotonic', '_join_multi', '_join_non_unique', '_join_precedence', '_left_indexer', '_left_indexer_unique', '_map_values', '_maybe_cast_indexer', '_maybe_cast_slice_bound', '_maybe_promote', '_maybe_update_attributes', '_mpl_repr', '_na_value', '_nan_idxs', '_ndarray_values', '_outer_indexer', '_reduce', '_reindex_non_unique', '_reset_cache', '_reset_identity', '_scalar_data_error', '_searchsorted_monotonic', '_set_names', '_shallow_copy', '_shallow_copy_with_infer', '_simple_new', '_sort_levels_monotonic', '_string_data_error', '_summary', '_to_safe_for_reshape', '_try_convert_to_int_index', '_typ', '_unpickle_compat', '_update_inplace', '_validate_for_numeric_binop', '_validate_for_numeric_unaryop', '_validate_index_level', '_validate_indexer', '_validate_names', '_validate_sort_keyword', '_values', '_wrap_joined_index', '_wrap_setop_result', 'all', 'any', 'append', 'argmax', 'argmin', 'argsort', 'array', 'asi8', 'asof', 'asof_locs', 'astype', 'contains', 'copy', 'delete', 'difference', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtype', 'dtype_str', 'duplicated', 'empty', 'equals', 'factorize', 'fillna', 'format', 'get_duplicates', 'get_indexer', 'get_indexer_for', 'get_indexer_non_unique', 'get_level_values', 'get_loc', 'get_slice_bound', 'get_value', 'get_values', 'groupby', 'has_duplicates', 'hasnans', 'holds_integer', 'identical', 'inferred_type', 'insert', 'intersection', 'is_', 'is_all_dates', 'is_boolean', 'is_categorical', 'is_floating', 'is_integer', 'is_interval', 'is_lexsorted_for_tuple', 'is_mixed', 'is_monotonic', 'is_monotonic_decreasing', 'is_monotonic_increasing', 'is_numeric', 'is_object', 'is_type_compatible', 'is_unique', 'isin', 'isna', 'isnull', 'item', 'join', 'map', 'max', 'memory_usage', 'min', 'name', 'names', 'nbytes', 'ndim', 'nlevels', 'notna', 'notnull', 'nunique', 'putmask', 'ravel', 'reindex', 'rename', 'repeat', 'searchsorted', 'set_names', 'set_value', 'shape', 'shift', 'size', 'slice_indexer', 'slice_locs', 'sort', 'sort_values', 'sortlevel', 'str', 'summary', 'symmetric_difference', 'take', 'to_flat_index', 'to_frame', 'to_list', 'to_native_types', 'to_numpy', 'to_series', 'transpose', 'union', 'unique', 'value_counts', 'values', 'view', 'where']\n"
     ]
    }
   ],
   "source": [
    "# Use values and index attributes on both Row and Column Indexes\n",
    "print(df.columns.values)\n",
    "print(dir(df.columns))#.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 43)\n",
      "Type        object\n",
      "Coverage    object\n",
      "OdName      object\n",
      "AREA         int64\n",
      "AreaName    object\n",
      "REG          int64\n",
      "RegName     object\n",
      "DEV          int64\n",
      "DevName     object\n",
      "1980         int64\n",
      "1981         int64\n",
      "1982         int64\n",
      "1983         int64\n",
      "1984         int64\n",
      "1985         int64\n",
      "1986         int64\n",
      "1987         int64\n",
      "1988         int64\n",
      "1989         int64\n",
      "1990         int64\n",
      "1991         int64\n",
      "1992         int64\n",
      "1993         int64\n",
      "1994         int64\n",
      "1995         int64\n",
      "1996         int64\n",
      "1997         int64\n",
      "1998         int64\n",
      "1999         int64\n",
      "2000         int64\n",
      "2001         int64\n",
      "2002         int64\n",
      "2003         int64\n",
      "2004         int64\n",
      "2005         int64\n",
      "2006         int64\n",
      "2007         int64\n",
      "2008         int64\n",
      "2009        object\n",
      "2010        object\n",
      "2011        object\n",
      "2012        object\n",
      "2013        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check Shape, Datatypes and other attributes\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type Coverage          OdName  AREA AreaName   REG  \\\n",
      "224  Immigrants     Both     Afghanistan   935     Asia  5501   \n",
      "225  Immigrants     Both         Albania   908   Europe   925   \n",
      "226  Immigrants     Both         Algeria   903   Africa   912   \n",
      "227  Immigrants     Both  American Samoa   909  Oceania   957   \n",
      "228  Immigrants     Both         Andorra   908   Europe   925   \n",
      "\n",
      "             RegName  DEV             DevName  1980  ...  2004  2005  2006  \\\n",
      "224    Southern Asia  902  Developing regions    10  ...    80   110   180   \n",
      "225  Southern Europe  901   Developed regions     0  ...   140   130   110   \n",
      "226  Northern Africa  902  Developing regions    10  ...    20    50    30   \n",
      "227        Polynesia  902  Developing regions     0  ...     0     0     0   \n",
      "228  Southern Europe  901   Developed regions     0  ...    10    10     0   \n",
      "\n",
      "     2007  2008  2009  2010  2011  2012  2013  \n",
      "224   140   560    ..    ..    ..    ..    ..  \n",
      "225   110   140    ..    ..    ..    ..    ..  \n",
      "226    30    60    ..    ..    ..    ..    ..  \n",
      "227     0    10    ..    ..    ..    ..    ..  \n",
      "228    10    10    ..    ..    ..    ..    ..  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Delete all Data where the Type = \"Emigrants\" or Type is not \"Immigrants\" (Row Deletion)\n",
    "data_to_delete = df[df.Type == 'Emigrants']\n",
    "df.drop(data_to_delete.index, inplace = True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type  Coverage  OdName  AREA  AreaName  REG  RegName  DEV  DevName  1980  \\\n",
      "0   224       224     224   224       224  224      224  224      224   224   \n",
      "\n",
      "   ...  2004  2005  2006  2007  2008  2009  2010  2011  2012  2013  \n",
      "0  ...   224   224   224   224   224   224   224   224   224   224  \n",
      "\n",
      "[1 rows x 43 columns]\n",
      "           Type Coverage          OdName  AREA AreaName   REG  \\\n",
      "224  Immigrants     Both     Afghanistan   935     Asia  5501   \n",
      "225  Immigrants     Both         Albania   908   Europe   925   \n",
      "226  Immigrants     Both         Algeria   903   Africa   912   \n",
      "227  Immigrants     Both  American Samoa   909  Oceania   957   \n",
      "228  Immigrants     Both         Andorra   908   Europe   925   \n",
      "\n",
      "             RegName  DEV             DevName  1980  ...  1999  2000  2001  \\\n",
      "224    Southern Asia  902  Developing regions    10  ...   270   100    20   \n",
      "225  Southern Europe  901   Developed regions     0  ...    70   110   110   \n",
      "226  Northern Africa  902  Developing regions    10  ...    30    20    30   \n",
      "227        Polynesia  902  Developing regions     0  ...     0     0     0   \n",
      "228  Southern Europe  901   Developed regions     0  ...    10     0    10   \n",
      "\n",
      "     2002  2003  2004  2005  2006  2007  2008  \n",
      "224    40    70    80   110   180   140   560  \n",
      "225   200   250   140   130   110   110   140  \n",
      "226    60    20    20    50    30    30    60  \n",
      "227     0     0     0     0     0     0    10  \n",
      "228    10     0    10    10     0    10    10  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find columns for which more than 50% data is missing and drop them (Column Deletion)\n",
    "print(df.isna().count().to_frame().T) # check any missing data\n",
    "# to_frame().T is just to display in single row instead of as a column\n",
    "\n",
    "# actually data contains ''..'' instead of Nan\n",
    "# either replace .. with Nan and then drop or just drop data with ..\n",
    "df.replace('..', np.nan, inplace = True)\n",
    "df.dropna(axis = 1, inplace = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  'OdName', 'AreaName',  'RegName',  'DevName',       1980,       1981,\n",
      "             1982,       1983,       1984,       1985,       1986,       1987,\n",
      "             1988,       1989,       1990,       1991,       1992,       1993,\n",
      "             1994,       1995,       1996,       1997,       1998,       1999,\n",
      "             2000,       2001,       2002,       2003,       2004,       2005,\n",
      "             2006,       2007,       2008],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop Unnessary Columns: Type, Coverage, Area, Reg, Dev (Column deletion)\n",
    "# Your columns should now look like \"OdName,AreaName,RegName,DevName,1980 ... 2008\"\n",
    "df.drop(columns = ['Type', 'Coverage', 'AREA', 'REG', 'DEV'], inplace = True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'Country', 'AreaName',   'Region',  'DevName',       1980,       1981,\n",
      "             1982,       1983,       1984,       1985,       1986,       1987,\n",
      "             1988,       1989,       1990,       1991,       1992,       1993,\n",
      "             1994,       1995,       1996,       1997,       1998,       1999,\n",
      "             2000,       2001,       2002,       2003,       2004,       2005,\n",
      "             2006,       2007,       2008],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename columns :OdName -> Country; RegName -> Region\n",
    "df.rename({'OdName': 'Country', 'RegName': 'Region'}, axis = 1, inplace = True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008]\n",
      "\n",
      "{1980: '1980', 1981: '1981', 1982: '1982', 1983: '1983', 1984: '1984', 1985: '1985', 1986: '1986', 1987: '1987', 1988: '1988', 1989: '1989', 1990: '1990', 1991: '1991', 1992: '1992', 1993: '1993', 1994: '1994', 1995: '1995', 1996: '1996', 1997: '1997', 1998: '1998', 1999: '1999', 2000: '2000', 2001: '2001', 2002: '2002', 2003: '2003', 2004: '2004', 2005: '2005', 2006: '2006', 2007: '2007', 2008: '2008'}\n",
      "Index(['Country', 'AreaName', 'Region', 'DevName', '1980', '1981', '1982',\n",
      "       '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991',\n",
      "       '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000',\n",
      "       '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert Column Names with Int type to Strings to avoid index errors with string indexing \"1980, 1981 etc.\" => \" '1980', '1981' ... \" (Use rename)\n",
    "\n",
    "columns_int = filter(lambda x: isinstance(x, int), df.columns)  # gives columns which are int\n",
    "columns_int = list(columns_int)\n",
    "\n",
    "# create a map of int and string columns\n",
    "columns_map = dict(   map(   lambda x: (x,str(x)), columns_int  )    )\n",
    "print(columns_int); print()\n",
    "print(columns_map)\n",
    "\n",
    "df.rename(columns_map, axis = 1, inplace = True)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Country AreaName           Region             DevName  1980  1981  \\\n",
      "224     Afghanistan     Asia    Southern Asia  Developing regions    10    20   \n",
      "225         Albania   Europe  Southern Europe   Developed regions     0     0   \n",
      "226         Algeria   Africa  Northern Africa  Developing regions    10    50   \n",
      "227  American Samoa  Oceania        Polynesia  Developing regions     0     0   \n",
      "228         Andorra   Europe  Southern Europe   Developed regions     0     0   \n",
      "\n",
      "     1982  1983  1984  1985  ...  2000  2001  2002  2003  2004  2005  2006  \\\n",
      "224    30    30    70   100  ...   100    20    40    70    80   110   180   \n",
      "225     0     0     0     0  ...   110   110   200   250   140   130   110   \n",
      "226    30    10    20    20  ...    20    30    60    20    20    50    30   \n",
      "227     0     0     0    20  ...     0     0     0     0     0     0     0   \n",
      "228    10     0     0     0  ...     0    10    10     0    10    10     0   \n",
      "\n",
      "     2007  2008  Total  \n",
      "224   140   560   4630  \n",
      "225   110   140   1910  \n",
      "226    30    60    730  \n",
      "227     0    10     30  \n",
      "228    10    10    100  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find Total number of immigrants for all years, and create a new column Total in data Frame\n",
    "df['Total'] = df.loc['1980':].sum(axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Country          AreaName  \\\n",
      "447                                              Total             World   \n",
      "432  United Kingdom of Great Britain and Northern I...            Europe   \n",
      "367                                        New Zealand           Oceania   \n",
      "434                           United States of America  Northern America   \n",
      "266     China, Hong Kong Special Administrative Region              Asia   \n",
      "\n",
      "                        Region             DevName    1980    1981    1982  \\\n",
      "447                      World               World  184290  212690  195200   \n",
      "432            Northern Europe   Developed regions   43540   57050   51730   \n",
      "367  Australia and New Zealand   Developed regions   34370   34440   23920   \n",
      "434           Northern America   Developed regions   10470   12080   12490   \n",
      "266               Eastern Asia  Developing regions    4170    4380    4980   \n",
      "\n",
      "       1983    1984    1985  ...    2000    2001    2002    2003    2004  \\\n",
      "447  153570  153530  172550  ...  317560  356410  361990  388450  350990   \n",
      "432   31660   25150   27630  ...   51000   52940   57330   70150   53140   \n",
      "367   13620   16900   27070  ...   47230   45570   29500   28000   40710   \n",
      "434   11110   11840   12480  ...   18030   19230   18950   18980   18540   \n",
      "266    5480    7450    6820  ...   16410   18620   20200   19220    9740   \n",
      "\n",
      "       2005    2006    2007    2008    Total  \n",
      "447  363470  402210  460650  535970  7965110  \n",
      "432   53300   57250   61490   65160  1333340  \n",
      "367   44680   45550   39120   46960   898760  \n",
      "434   18490   17320   19260   20860   450370  \n",
      "266   10070   10270    9680   11030   388640  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort Data by the new column Total in descending order and analyze the fist few rows. (get first few rows using head)\n",
    "#     find something weird in the dataset ? Delete that row 'world'\n",
    "print(df.sort_values(by = 'Total', ascending = False).head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze last few rows also in the sorted result (Don't sort inplace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "     224    225    226    227    228    229    230    231    232    233  ...  \\\n",
      "0  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "\n",
      "     438    439    440    441    442    443    444    445    446    447  \n",
      "0  False  False  False  False  False  False  False  False  False  False  \n",
      "\n",
      "[1 rows x 224 columns]\n",
      "Duplicate Pairs :  False\n"
     ]
    }
   ],
   "source": [
    "# Check if these have all unique values or not:\n",
    "#   - countries\n",
    "#   - continents\n",
    "#   - country continent pairs\n",
    "\n",
    "print(df.Country.is_unique)\n",
    "print(df.AreaName.is_unique)\n",
    "\n",
    "# get a series containing True for any duplicate  pair\n",
    "duplicates = df.duplicated(subset = ['Country', 'AreaName'], )\n",
    "print(duplicates.to_frame().T)\n",
    "\n",
    "print(\"Duplicate Pairs : \", duplicates.any()) # finally check if any row is duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230                            Anguilla\n",
      "262            Central African Republic\n",
      "270                             Comoros\n",
      "306                           Greenland\n",
      "308                          Guadeloupe\n",
      "315                            Holy See\n",
      "353                             Mayotte\n",
      "392                        Saint Helena\n",
      "393               Saint Kitts and Nevis\n",
      "395    Saint Vincent and the Grenadines\n",
      "427            Turks and Caicos Islands\n",
      "435        United States Virgin Islands\n",
      "442                      Western Sahara\n",
      "Name: Country, dtype: object\n",
      "\n",
      "13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find countries for which no of immigrants for all years is 0\n",
    "print(df[df.Total == 0].Country); print()\n",
    "# Find count of above countries\n",
    "print(df[df.Total == 0].Country.size); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225                                      Albania\n",
      "227                               American Samoa\n",
      "228                                      Andorra\n",
      "229                                       Angola\n",
      "230                                     Anguilla\n",
      "231                          Antigua and Barbuda\n",
      "233                                      Armenia\n",
      "234                                        Aruba\n",
      "235                                    Australia\n",
      "237                                   Azerbaijan\n",
      "238                                      Bahamas\n",
      "241                                     Barbados\n",
      "242                                      Belarus\n",
      "244                                       Belize\n",
      "245                                        Benin\n",
      "247                                       Bhutan\n",
      "249                       Bosnia and Herzegovina\n",
      "252                       British Virgin Islands\n",
      "255                                 Burkina Faso\n",
      "256                                      Burundi\n",
      "257                                   Cabo Verde\n",
      "258                                     Cambodia\n",
      "259                                     Cameroon\n",
      "261                               Cayman Islands\n",
      "262                     Central African Republic\n",
      "263                                         Chad\n",
      "270                                      Comoros\n",
      "271                                        Congo\n",
      "274                                Côte d'Ivoire\n",
      "275                                      Croatia\n",
      "                         ...                    \n",
      "387                          Republic of Moldova\n",
      "388                                      Réunion\n",
      "390                           Russian Federation\n",
      "391                                       Rwanda\n",
      "392                                 Saint Helena\n",
      "393                        Saint Kitts and Nevis\n",
      "394                                  Saint Lucia\n",
      "395             Saint Vincent and the Grenadines\n",
      "398                                      Senegal\n",
      "400                                 Sierra Leone\n",
      "402                                     Slovakia\n",
      "403                                     Slovenia\n",
      "405                                      Somalia\n",
      "409                           State of Palestine\n",
      "411                                     Suriname\n",
      "416                                   Tajikistan\n",
      "418    The former Yugoslav Republic of Macedonia\n",
      "419                                  Timor-Leste\n",
      "420                                         Togo\n",
      "421                                      Tokelau\n",
      "424                                      Tunisia\n",
      "426                                 Turkmenistan\n",
      "427                     Turks and Caicos Islands\n",
      "428                                       Tuvalu\n",
      "430                                      Ukraine\n",
      "435                 United States Virgin Islands\n",
      "437                                   Uzbekistan\n",
      "441                    Wallis and Futuna Islands\n",
      "442                               Western Sahara\n",
      "443                                        Yemen\n",
      "Name: Country, Length: 121, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find countries for which no of immigrants is 0 for any year\n",
    "idx = (df.loc['1980':] == 0).any(1) # index of countries where any row has zero\n",
    "print( df.Country[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Country AreaName           Region             DevName  \\\n",
      "441  Wallis and Futuna Islands  Oceania        Polynesia  Developing regions   \n",
      "442             Western Sahara   Africa  Northern Africa  Developing regions   \n",
      "443                      Yemen     Asia     Western Asia  Developing regions   \n",
      "444                     Zambia   Africa   Eastern Africa  Developing regions   \n",
      "445                   Zimbabwe   Africa   Eastern Africa  Developing regions   \n",
      "\n",
      "     1980  1981  1982  1983  1984  1985  ...  2000  2001  2002  2003  2004  \\\n",
      "441     0     0     0     0     0     0  ...     0     0     0     0    10   \n",
      "442     0     0     0     0     0     0  ...     0     0     0     0     0   \n",
      "443    10     0     0    10    20    10  ...    20    60    40   150    40   \n",
      "444   150   110   120   180   130   170  ...   100   190   260   430   370   \n",
      "445   630  1120  1190   980   640   500  ...   910  1500  1670  2330  1790   \n",
      "\n",
      "     2005  2006  2007  2008  Total  \n",
      "441     0     0     0     0     10  \n",
      "442     0     0     0     0      0  \n",
      "443    20    10    40    40    570  \n",
      "444   240   410   410   400   5590  \n",
      "445  1560  1880  2180  2270  27350  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the row where AreaName is 'World'\n",
    "df.drop( df.index[df.AreaName == 'World'], inplace = True )\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to a new file AustraliaFiltered.xlsx\n",
    "df.to_excel('AustraliaFiltered.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
